{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **DO NOT EDIT IF INSIDE `computational_analysis_of_big_data_2018_spring` folder** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: Machine Learning 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Thursday, February 22, 2018*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T15:30:03.634114Z",
     "start_time": "2017-08-23T15:30:03.629294Z"
    }
   },
   "source": [
    "There are innumerable machine learning models (and algorithms for fitting them to data) out there, and each one has something special about it that makes it suitable to a specific type of problem. To apply machine learning and get some initial results is fairly straight forward. Getting under the hood, however, requires a bit of work. This week we will look into how Decision Trees and PCA works. In the exercises today you will:\n",
    "\n",
    "* Implement a standard decision tree mechanism\n",
    "* Use PCA to visualize clusters in your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**: Outside of class, use [issue on GitHub](https://github.com/ulfaslak/computational_analysis_of_big_data_2018_spring/issues) for asking questions.\n",
    "\n",
    "**Feedback:** Am I going too fast over things? Overexplaining? Send me anonymous feedback about the exercises, lectures and course in general at http://ulfaslak.com/vent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get started**: Load the data you used last week to classify hero/villainness. It should consist of two arrays, one of dimensions ($N_{characters}$, $N_{teams}$) which is your feature matrix that has the team alliances of each character as a row vector of ones and zeros, and another of dimensions ($N_{characters}$, ) which is your target array that gives whether a character is a hero (1) or a villain (0). You can either load the data or copy/paste the code that generates it.\n",
    "\n",
    "*Hint: If you had trouble with the data, use mine. You can load it as a `pandas.DataFrame`, with `pd.read_csv('data_team_alliances.csv', index_col=0)`. The rightmost column is the target array. Do not include this in PCA (think about why)!.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will implement the decision making algorithm of a decision tree classifier, step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    ">**Ex. 5.1.1**: Read about [Shannon entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory).\n",
    "1. What is it? How is it defined mathematically (write out the formula in LateX formatting)?\n",
    "2. Write a function that computes the Shannon-entropy of a probability vector. Compute the Shannon entropy of `p=[0.4, 0.6]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    ">**Ex. 5.1.2**: Split your data into two subsets. One where characters are affiliated with X-men and one where they are not.\n",
    "1. What is the entropy of target labels in each subset?\n",
    "2. What is the weighted average entropy of the split?\n",
    "3. Write a function that computes the weighted average entropy of a split, given the data and team (name or id) on which to split the data.\n",
    "4. Plot the distribution of split entropy for all features. Comment on the result. My figure looks [like this](http://ulfaslak.com/computational_analysis_of_big_data/exer_figures/example_6.2.2.4.png)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    ">**Ex. 5.1.3**: Print the maximum entropy path of a decision tree.\n",
    ">\n",
    ">1. Implement the following pseudocode and print the output:<br><br>\n",
    ">Step 1. Find `team` that gives lowest split entropy for `data`. Print `team`.<br>\n",
    ">Step 2. Split `data` on `team`, to produce `data0` and `data1`. Print the entropy of each, as well as their weighted avg. entropy.<br>\n",
    ">Step 3. Overwrite the `data` variable with either `data0` or `data1`, depending on which has the highest entropy.<br>\n",
    ">Step 4. Stop if there are less than 5 datapoints in `data`. Otherwise start over from 1.<br><br>\n",
    ">My output looks [like this](http://ulfaslak.com/computational_analysis_of_big_data/exer_figures/example_6.2.3.1.png) for the first five splits.<br><br>\n",
    ">\n",
    ">2. Comment on decision path your code takes: How splits are there? Do you notice anything interesting about the final splits? Why do we choose to stop splitting before `data` get smaller than 5?\n",
    ">3. Train a `sklearn.tree.DecisionTreeClassifier` classifier on the dataset. Initiate the classifier with `criterion='entropy'`. What are the most important features of this classifier? How does this line up with the order of the order of splits you just printed (a comment is fine)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle component analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of this exercise is to learn how to visualize high-dimensional data, and get a feeling of how your Marvel data looks when projected to a plane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    ">**Ex. 5.2.1**: Apply a PCA to your data. If `X` is your feature matrix, a PCA can be done like:\n",
    "\n",
    ">        pca = sklearn.decomposition.PCA()\n",
    ">        pca.fit(X)\n",
    ">        X_pca = pca.transform(X)\n",
    "\n",
    ">1. What is the dimensionality of `X_pca` compared to `X`? What happened to `X` when you transformed it?\n",
    "2. Plot the first two components/columns of the transformed data and color the points by their class label. My plot looks [like this](http://ulfaslak.com/computational_analysis_of_big_data/exer_figures/example_6.1.1.2.png). Comment on the result. What would plotting two other components against each other show you?\n",
    "3. Plot the explained variance ratio of each component. What does this tell you about the dataset? My plot looks [like this](http://ulfaslak.com/computational_analysis_of_big_data/exer_figures/example_6.1.1.3.png).\n",
    "\n",
    ">*Hint for 2: `plt.scatter` takes an argument `color` which must receive either a string such as `red` or `blue`, or a list of rgb values or strings such as `['red', 'blue', 'blue', ...]`.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
